<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>Getting Started - OpenTSDB - A Distributed, Scalable Monitoring System</title>
<link rel="stylesheet" href="css/style.css" type="text/css" media="screen"/>
<!--[if lte IE 8]>
<link rel="stylesheet" href="css/ie.css" type="text/css" media="screen"/>
<![endif]-->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-18339382-1']);
  _gaq.push(['_setDomainName', 'none']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body>
<header><div id="headerbar">
  <h1><a href="index.html">OpenTSDB</a></h1>
  <nav><ul id="navbar">
    <li><a href="overview.html">Overview</a></li>
    <li><a href="getting-started.html">Getting Started</a></li>
    <li><a href="manual.html">Manual</a></li>
    <li><a href="faq.html">FAQ</a></li>
  </ul></nav>
</div></header>

<!--[if lte IE 8]>
<div class="iesucks">Warning: You're using an unsupported, archaic browser.
Get a better, modern browsing experience with
<a href="http://www.google.com/chrome">Chrome</a> or
<a href="http://www.mozilla.com/firefox">Firefox</a>.</div>
<![endif]-->
<section id="content">
<section id="gettingstarted">
<h2>Getting Started</h2>
This page will walk you through the setup process to get OpenTSDB running.
It assumes you've read and understood the <a href="overview.html">overview</a>.
With no prior experience, it should take about 15 minutes to get OpenTSDB
running, including the time needed to <a href="setup-hbase.html">setup HBase
on a single node</a>.

<h2 class="setup">Setting up OpenTSDB</h2>
<div style="float:right">
Additional compile-time dependencies:
<ul>
<li><a href="http://gwt.google.com">GWT</a> 2.4 (ASLv2)</li>
</ul>
Additional unit test dependencies:
<ul>
<li><a href="http://www.javassist.org">Javassist</a> 3.15 (MPL / LGPL)</li>
<li><a href="http://www.junit.org">JUnit</a> 4.10 (CPL)</li>
<li><a href="http://mockito.org">Mockito</a> 1.9 (MIT)</li>
<li><a href="http://code.google.com/p/powermock/">PowerMock</a> 1.4 (ASLv2)</li>
</ul>
</div>
OpenTSDB comes pre-packaged with all the necessary dependencies except the
JDK and Gnuplot.<br/>The runtime dependencies for OpenTSDB are:
<ul>
<li>JDK 1.6</li>
<li><a href="http://github.com/OpenTSDB/asynchbase">asynchbase</a> 1.3.0 (BSD)</li>
<li><a href="http://code.google.com/p/guava-libraries/">Guava</a> 12.0 (ASLv2)</li>
<li><a href="http://logback.qos.ch/">logback</a> 1.0 (LGPLv2.1 / EPL)</li>
<li><a href="http://jboss.org/netty">Netty</a> 3.4 (ASLv2)</li>
<li><a href="http://slf4j.org">SLF4J</a> 1.6 (MIT) with Log4J and JCL adapters</li>
<li><a href="http://github.com/OpenTSDB/async">suasync</a> 1.2 (BSD)</li>
<li><a href="http://hadoop.apache.org/zookeeper/">ZooKeeper</a> 3.3 (ASLv2)</li>
</ul>
You need to have <a href="http://www.gnuplot.info/">Gnuplot</a> (custom
open-source license) installed in your <code>PATH</code> version 4.2 minimum,
4.4 recommended.
<p>
Before getting started, you need an instance of
<a href="http://hbase.org">HBase</a> 0.94 (ASLv2) up and running.
If you don't already have one, you can <a href="setup-hbase.html">get started
quickly with a single-node HBase instance</a>.  Earlier versions of HBase will
work too, but being on the last major release is heavily recommended.
<p>
Almost all the following instructions can be copy-pasted directly into a
terminal on a Linux or Mac OS X (or otherwise POSIXy) machine.  You will need
to edit the placeholders which are typeset <code><b><i>like-this</i></b></code>.
A Bourne shell (such as <code>bash</code> or <code>zsh</code>) is assumed.
No special privileges are required.

<a name="setuptsdb"></a>
<h3>Checkout, compile &amp; start OpenTSDB</h3>
OpenTSDB uses the usual build process that consists in running
<code>./bootstrap</code> (only once, when you first check out the code),
followed by <code>./configure</code> and <code>make</code>.  There is a
handy shell script named <code>build.sh</code> that will take care of all
of that for you, and build OpenTSDB in a new subdirectory named
<code>build</code>:
<div class="code">git clone git://github.com/OpenTSDB/opentsdb.git
cd opentsdb
./build.sh
</div>
From there on, you can use the command-line tool by invoking
<code>./build/tsdb</code> or you can run <code>make install</code> to install
OpenTSDB on your system.  Should you ever change your mind, there is also
<code>make uninstall</code>, so there are no strings attached.
<p>
If it's the first time you run OpenTSDB with your HBase instance, you first
need to create the necessary HBase tables:
<div class="code">env COMPRESSION=NONE HBASE_HOME=<b><i>path/to/hbase-0.94.X</i></b> ./src/create_table.sh
</div>
This will create two tables: <code>tsdb</code> and <code>tsdb-uid</code>.
If you're just evaluating OpenTSDB, don't worry about compression for now.  In
production / at scale, make sure you use <code>COMPRESSION=lzo</code> and have
<a href="setup-hbase.html#lzo">LZO enabled</a>.
<p>
Now start a TSD (Time Series Daemon):
<div class="code">tsdtmp=${TMPDIR-'/tmp'}/tsd    <i># For best performance, make sure</i>
mkdir -p "$tsdtmp"             <i># your temporary directory uses tmpfs</i>
./build/tsdb tsd --port=4242 --staticroot=build/staticroot --cachedir="$tsdtmp"
</div>
If you're using a real HBase cluster, you will also need to pass the
<code>--zkquorum</code> flag to specify the comma-separated list of hosts
serving your ZooKeeper quorum.  The <code>--cachedir</code> can be purged
periodically, e.g. by a cron job.
<p>
At this point you can access the TSD's web interface through
<a href="http://127.0.0.1:4242">127.0.0.1:4242</a> (if it's running on your
local machine).

<h2>Using OpenTSDB</h2>

<a name="mkmetrics"></a>
<h3>Create your first metrics</h3>
Metrics need to be registered before you can start storing data points for
them.
<div class="code">./tsdb mkmetric mysql.bytes_received mysql.bytes_sent</div>
This will create 2 metrics: <code>mysql.bytes_received</code> and
<code>mysql.bytes_sent</code>
<p>
New tags, on the other hand, are automatically registered whenever
they're used for the first time.  Right now OpenTSDB only allows you
to have up to 2<sup>24</sup> = 16777216 different metrics, 16777216
different tag names and 16777216 different tag values.  This is because
each one of those is assigned a UID on 3 bytes.  Metric names, tag names
and tag values have their own UID spaces, which is why you can have
16777216 of each kind.  The size of each space is configurable but there
is no knob that exposes this configuration parameter right now.  So bear
in mind that using user ID or event ID as a tag value will not work right
now if you have a large site.

<a name="collect"></a>
<h3>Start collecting data</h3>
So now that we have our 2 metrics, we can start sending data to the TSD.
Let's write a little shell script to collect some data off of MySQL and
send it to the TSD (note: this is just an example, in practice you can
use <a href="https://github.com/OpenTSDB/tcollector/blob/master/collectors/0/mysql.py">tcollector's MySQL collector</a>.):
<div class="code">cat &gt;mysql-collector.sh &lt;&lt;\EOF
#!/bin/bash
set -e
while true; do
  mysql -u <b><i>USER</i></b> -p<b><i>PASS</i></b> --batch -N --execute "SHOW STATUS LIKE 'bytes%'" \
  | awk -F"\t" -v now=`date +%s` -v host=`hostname` \
      '{ print "put mysql." tolower($1) " " now " " $2 " host=" host }'
  sleep 15
done | nc -w 30 <b><i>host.name.of.tsd</i></b> <b><i>PORT</i></b>
EOF
chmod +x mysql-collector.sh
nohup ./mysql-collector.sh &
</div>
Every 15 seconds, the script will collect 2 data points from MySQL and send
them to the TSD.  You can use a smaller sleep interval for more real-time
monitoring, but remember you can't have sub-second precision, so you must
sleep at least 1 second before producing another data point.
<p>
What does the script do?  If you're not a big fan of shell and
<code>awk</code> scripting, it may not be obvious how this works.
But it's simple.  The <code>set -e</code> command simply instructs
<code>bash</code> to exit with an error if any of the commands fail.
This simplifies error handling.  The script then enters an infinite loop.
In this loop, we query MySQL to retrieve 2 of its status variables: 
<div class="code">$ mysql -u <b><i>USER</i></b> -p<b><i>PASS</i></b> --execute "SHOW STATUS LIKE 'bytes%'"
+----------------+-------+
| Variable_name  | Value |
+----------------+-------+
| Bytes_received | 133   |
| Bytes_sent     | 190   |
+----------------+-------+
</div>
The <code>--batch -N</code> flags ask the <code>mysql</code> command to
remove the human friendly fluff so we don't have to filter it out ourselves.
Then the output is piped to <code>awk</code>, which is told to split fields on
tabs (<code>-F"\t"</code>) because with the <code>--batch</code> flag that's
what <code>mysql</code> will use.  We also create a couple of variables, one
named <code>now</code> and initialize it to the current timestamp, the other
named <code>host</code> and set to the hostname of the local machine.  Then,
for every line, we print <code>put mysql.</code>, followed by the lower-case
form of the first word, then by a space, then by the current timestamp, then
by the second word (the value), another space, and finally <code>host=</code>
and the current hostname.  Rinse and repeat every 15 seconds.  The <code>-w
30</code> parameter given to <code>nc</code> simply sets a timeout on the
connection to the TSD.
<p>
Bear in mind, this is just an example, in practice you can use
<a href="https://github.com/OpenTSDB/tcollector/blob/master/collectors/0/mysql.py">tcollector's MySQL collector</a>.
<p>
If you don't have a MySQL server to monitor, you can try this instead to
collect basic load metrics from your Linux servers.
<div class="code">cat &gt;loadavg-collector.sh &lt;&lt;\EOF
#!/bin/bash
set -e
while true; do
  awk -v now=`date +%s` -v host=`hostname` \
  '{ print "put proc.loadavg.1m " now " " $1 " host=" host;
     print "put proc.loadavg.5m " now " " $2 " host=" host }' /proc/loadavg
  sleep 15
done | nc -w 30 <b><i>host.name.of.tsd</i></b> <b><i>PORT</i></b>
EOF
chmod +x loadavg-collector.sh
nohup ./loadavg-collector.sh &
</div>
This will store a reading of the 1-minute and 5-minute load average of your
server in OpenTSDB by sending simple "telnet-style commands" to the TSD:
<div class="code">put proc.loadavg.1m 1288946927 0.36 host=foo
put proc.loadavg.5m 1288946927 0.62 host=foo
put proc.loadavg.1m 1288946942 0.43 host=foo
put proc.loadavg.5m 1288946942 0.62 host=foo
</div>

<a name="batchimport"></a>
<h3>Batch imports</h3>
Let's imagine that you have a cron job that crunches gigabytes of application
logs every day or every hour to extract profiling data.  For instance, you
could be logging the time taken to process a request and your cron job would
compute an average for every 30 second window.  Maybe you're particularly
interested in 2 types of requests handled by your application, so you'll
compute separate averages for those requests, and an another average for every
other request type.  So your cron job may produce an output file that looks
like this:
<div class="code">1288900000 42 foo
1288900000 51 bar
1288900000 69 other
1288900030 40 foo
1288900030 59 bar
1288900030 80 other
</div>
The first column is a timestamp, the second the average latency for that 30
second window, and the third the type of request we're talking about.  If you
run your cron job on a day worth of logs, you'll end up with 8640 such lines.
In order to import those into OpenTSDB, you need to adjust your cron job
slightly to produce its output in the following format:
<div class="code">myservice.latency.avg 1288900000 42 reqtype=foo
myservice.latency.avg 1288900000 51 reqtype=bar
myservice.latency.avg 1288900000 69 reqtype=other
myservice.latency.avg 1288900030 40 reqtype=foo
myservice.latency.avg 1288900030 59 reqtype=bar
myservice.latency.avg 1288900030 80 reqtype=other
</div>
Notice we're simply associating each data point with the name of a metric
(<code>myservice.latency.avg</code>) and naming the tag that represents the
request type.  If each server has its own logs and you process them
separately, you may want to add another tag to each line like the
<code>host=foo</code> tag we saw in the previous section.  This way you'll
be able to plot the latency of each server individually, in addition to your
average latency across the board and/or per request type.
<p>
In order to import a data file in the format above (<code>metric timestamp
value tags</code>) simply run the following command:
<div class="code">./tsdb import <b><i>your-file</i></b></div>
If your data file is large, consider <code>gzip</code>'ing it first.  This can
be as simple as piping the output of your cron job to
<code>gzip -9 &gt;output.gz</code> instead of writing directly to a file.  The
<code>import</code> command is able to read <code>gzip</code>'ed files and it
greatly helps performance for large batch imports.

<a name="selfmonitoring"></a>
<h3>Self monitoring</h3>
Each TSD exports some stats about itself through the simple <code>stats</code>
command.  You can collect those stats and feed them back to the TSD every few
seconds.  First, create the necessary metrics:
<div class="code">echo stats | nc -w 1 localhost 4242 \
| awk '{ print $1 }' | sort -u \
| xargs ./tsdb mkmetric</div>
This requests the stats from the TSD (assuming it's running on the local host
and listening to port 4242), extract the names of the metrics from the stats
and assigns them UIDs.
<p>
Then you can use this simple script to collect stats and store them in
OpenTSDB:
<div class="code">#!/bin/bash
INTERVAL=15
while :; do
  echo stats || exit
  sleep $INTERVAL
done | nc -w 30 localhost $1 \
     | sed 's/^/put /' \
     | nc -w 30 localhost $1</div>
This way you will collect and store stats from the TSD every 15 seconds.
</section>
<footer>
&copy; 2010&ndash;2013 The OpenTSDB Authors.
</footer>
</section></body></html>
