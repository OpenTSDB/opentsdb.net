<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Aggregation &#8212; OpenTSDB 3.0 documentation</title>
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><span><img src="../../_static/opentsdb_logo_square_sm.png"></span>
          OpenTSDB</a>
        <span class="navbar-text navbar-version pull-left"><b>3.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://github.com/OpenTSDB/opentsdb/releases">Download</a></li>
                <li><a href="https://github.com/OpenTSDB/opentsdb">Source</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Documentation <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Aggregation</a><ul>
<li><a class="reference internal" href="#id1">Aggregation</a></li>
<li><a class="reference internal" href="#interpolation">Interpolation</a></li>
<li><a class="reference internal" href="#downsampling">Downsampling</a></li>
<li><a class="reference internal" href="#available-aggregators">Available Aggregators</a><ul>
<li><a class="reference internal" href="#avg">Avg</a></li>
<li><a class="reference internal" href="#count">Count</a></li>
<li><a class="reference internal" href="#dev">Dev</a></li>
<li><a class="reference internal" href="#estimated-percentiles">Estimated Percentiles</a></li>
<li><a class="reference internal" href="#first-last">First &amp; Last</a></li>
<li><a class="reference internal" href="#max">Max</a></li>
<li><a class="reference internal" href="#mimmin">MimMin</a></li>
<li><a class="reference internal" href="#mimmax">MimMax</a></li>
<li><a class="reference internal" href="#min">Min</a></li>
<li><a class="reference internal" href="#none">None</a></li>
<li><a class="reference internal" href="#percentiles">Percentiles</a></li>
<li><a class="reference internal" href="#sum">Sum</a></li>
<li><a class="reference internal" href="#zimsum">ZimSum</a></li>
</ul>
</li>
<li><a class="reference internal" href="#listing-aggregators">Listing Aggregators</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    <div class="col-md-9 content">
      
  <div class="section" id="aggregation">
<h1>Aggregation</h1>
<p>OpenTSDB was designed to efficiently combine multiple, distinct time series during query execution. The reason for this is that when users are looking at their data, most often they start at a high level asking questions like &quot;what is my total throughput by data center?&quot; or &quot;what is the current power consumption by region?&quot;. After looking at these high level values, one or more may stick out so users drill-down into more granular data sets like &quot;what is the throughput by host in my LAX data center?&quot;. We want to make it easy to answer those high level questions but still allow for drilling down for greater detail.</p>
<p>But how do you merge multiple individual time series into a single series of data? Aggregation functions provide the means of mathematically merging the different time series into one. Filters are used to group results by tags and aggregations are then applied to each group. Aggregations are similar to SQL's <code class="docutils literal"><span class="pre">GROUP</span> <span class="pre">BY</span></code> clause where the user selects a pre-defined aggregation function to merge multiple records into a single result. However in TSDs, a set of records is aggregated per timestamp and group.</p>
<p>Each aggregator has two components:</p>
<ul class="simple">
<li><strong>Function</strong> - The mathematical computation applied such as summing all the values, computing the average or picking the highest.</li>
<li><strong>Interpolation</strong> - A way of handling <em>missing</em> values such as when time series <em>A</em> has a value at <em>T1</em> but time series <em>B</em> does not have a value.</li>
</ul>
<p>This document focuses on how aggregators are used in a <em>group by</em> context, i.e. when merging multiple time series into one. Additionally, aggregators can be used to downsample time series (i.e. return a lower resolution set of results). For more information, see <a class="reference internal" href="downsampling.html"><span class="doc">Downsampling</span></a>.</p>
<div class="section" id="id1">
<h2>Aggregation</h2>
<p>When aggregating or <em>grouping</em> each set of time series into one, the timestamps in every time series are aligned. Then for each timestamp, the values across all time series are aggregated into a new numerical value. That is, the aggregator will work <em>across</em> all of the time series at each timestamp. Think of the raw data as a matrix or table as in the following example that illustrates the <code class="docutils literal"><span class="pre">sum</span></code> aggregator as it works across two time series, <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code>, to produce a new time series <code class="docutils literal"><span class="pre">Output</span></code>.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="40%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Time Series</th>
<th class="head">t0</th>
<th class="head">t0+10s</th>
<th class="head">t0+20s</th>
<th class="head">t0+30s</th>
<th class="head">t0+40s</th>
<th class="head">t0+50s</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>A</td>
<td>5</td>
<td>5</td>
<td>10</td>
<td>15</td>
<td>20</td>
<td>5</td>
</tr>
<tr class="row-odd"><td>B</td>
<td>10</td>
<td>5</td>
<td>20</td>
<td>15</td>
<td>10</td>
<td>0</td>
</tr>
<tr class="row-even"><td>Output</td>
<td>15</td>
<td>10</td>
<td>30</td>
<td>30</td>
<td>30</td>
<td>5</td>
</tr>
</tbody>
</table>
<p>For timestamp <code class="docutils literal"><span class="pre">t0</span></code> the data points for <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code> are summed, i.e. <code class="docutils literal"><span class="pre">5</span> <span class="pre">+</span> <span class="pre">10</span> <span class="pre">==</span> <span class="pre">15</span></code>. Next, the two values for <code class="docutils literal"><span class="pre">ts1</span></code> are summed together to get <code class="docutils literal"><span class="pre">10</span></code> and so on. In SQL, this may look like <code class="docutils literal"><span class="pre">SELECT</span> <span class="pre">SUM(value)</span> <span class="pre">FROM</span> <span class="pre">ts_table</span> <span class="pre">GROUP</span> <span class="pre">BY</span> <span class="pre">timestamp</span></code>.</p>
</div>
<div class="section" id="interpolation">
<h2>Interpolation</h2>
<p>In the example above, both time series <code class="docutils literal"><span class="pre">A</span></code> and <code class="docutils literal"><span class="pre">B</span></code> had data points at every time stamp, they lined up neatly. However what happens when two series do not line up? It can be difficult, and sometimes undesired, to synchronize all sources of data to write at the exact same time. For example, if we have 10,000 servers sending 100 system metrics every 5 minutes, that would be a burst of 10M data points in a single second. We would need a pretty beefy network and cluster to accommodate that traffic. Not to mention the system would be sitting idle for 4 minutes and 59 seconds. Instead it makes much more sense to splay the writes over time so that we have an average of 3,333 writes per second to reduce our hardware and network requirements.</p>
<div class="sidebar">
<p class="first sidebar-title">Missing Data</p>
<p class="last">By &quot;missing&quot; we simply mean that a time series does not have a data point at a given timestamp. Usually the data is simply time shifted before or after the requested timestamp, but it could actually be missing if the source or the TSD encountered an error and the data wasn't recorded. Some time series DBs may allow for storing a <code class="docutils literal"><span class="pre">NaN</span></code> at a timestamp to represent an unrecordable value but OpenTSDB does not allow this yet.</p>
</div>
<p>How do you <em>sum</em> or find the <em>avg</em> of a number and something that doesn't exist? One's first instinct is to just return the valid data points and be done with it. However what if you're dealing, as above, with thousands of sources where the data points are simply unaligned? For example, the following graph shows a time series with writes that are unaligned, resulting in a jagged line that is confusing to read:</p>
<img alt="../../_images/aggregation_zimsum.png" src="../../_images/aggregation_zimsum.png" />
<p>Alternatively, you could simply ignore the data points for all time series at a given time stamp where any series is missing data. But if you have two time series and they are simply miss-aligned, your query would return an empty data set even though there is good data in storage, so that's not necessarily very useful.</p>
<p>Another option is to define a scalar value (e.g. <code class="docutils literal"><span class="pre">0</span></code> or the maximum value for a Long) to use whenever a data point is missing. OpenTSDB 2.0 and later provides a few aggregation methods that substitute a scalar value for missing data points and indeed, the graph above was generated using the <code class="docutils literal"><span class="pre">zimsum</span></code> aggregator that replaces unaligned values with a zero. This kind of substitution can be useful when working with distinct value time series such as the total number of sales in at a given time but doesn't work when dealing with averages or visually verifying a graph <em>looks</em> good.</p>
<p>One answer OpenTSDB provides is to use the well defined numerical analysis method of <a class="reference external" href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> to make a guess as to what the value would be at that point in time. Interpolation uses existing data points for a time series to calculate a <em>best guess</em> value at the time stamp requested. Using OpenTSDB's linear interpolation we can smooth out our unaligned graph to get:</p>
<img alt="../../_images/aggregation_sum.png" src="../../_images/aggregation_sum.png" />
<p>For a numerical example, take a look at these two time series where the sources issue a value every 20 seconds and the data is simply offset by 10 seconds:</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="30%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Time Series</th>
<th class="head">t0</th>
<th class="head">t0+10s</th>
<th class="head">t0+20s</th>
<th class="head">t0+30s</th>
<th class="head">t0+40s</th>
<th class="head">t0+50s</th>
<th class="head">t0+60s</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>A</td>
<td><em>na</em></td>
<td>5</td>
<td><em>na</em></td>
<td>15</td>
<td><em>na</em></td>
<td>5</td>
<td><em>na</em></td>
</tr>
<tr class="row-odd"><td>B</td>
<td>10</td>
<td><em>na</em></td>
<td>20</td>
<td><em>na</em></td>
<td>10</td>
<td><em>na</em></td>
<td>20</td>
</tr>
</tbody>
</table>
<p>When OpenTSDB is calculating an aggregation it starts at the first data point found for any series, in this case it will be the data for <code class="docutils literal"><span class="pre">B</span></code> at <code class="docutils literal"><span class="pre">t0</span></code>. We request a value for <code class="docutils literal"><span class="pre">A</span></code> at <code class="docutils literal"><span class="pre">t0</span></code> but there isn't any data there. We know that there is data for <code class="docutils literal"><span class="pre">A</span></code> at <code class="docutils literal"><span class="pre">t0+10s</span></code> but since we don't have any value before that, we can't make a guess as to what it would be. Thus we simply return the value for <code class="docutils literal"><span class="pre">B</span></code>.</p>
<p>Next we run across a value for <code class="docutils literal"><span class="pre">A</span></code> at time <code class="docutils literal"><span class="pre">t0+10s</span></code>. We request a value for <code class="docutils literal"><span class="pre">t0+10s</span></code> from time series <code class="docutils literal"><span class="pre">B</span></code> but there isn't one. But <code class="docutils literal"><span class="pre">B</span></code> knows there is a value at <code class="docutils literal"><span class="pre">t0+20s</span></code> and we had a value at <code class="docutils literal"><span class="pre">t0</span></code> so we can now calculate a guess for <code class="docutils literal"><span class="pre">t0+10s</span></code>. The formula for linear interpolation is <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">y0</span> <span class="pre">+</span> <span class="pre">(y1</span> <span class="pre">-</span> <span class="pre">y0)</span> <span class="pre">*</span> <span class="pre">((x</span> <span class="pre">-</span> <span class="pre">x0)</span> <span class="pre">/</span> <span class="pre">(x1</span> <span class="pre">-</span> <span class="pre">x0))</span></code> where, for series <code class="docutils literal"><span class="pre">B</span></code>, <code class="docutils literal"><span class="pre">y0</span> <span class="pre">=</span> <span class="pre">10</span></code>, <code class="docutils literal"><span class="pre">y1</span> <span class="pre">=</span> <span class="pre">20</span></code>, <code class="docutils literal"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">t0+10s</span> <span class="pre">(or</span> <span class="pre">10)</span></code>, <code class="docutils literal"><span class="pre">x0</span> <span class="pre">=</span> <span class="pre">t0</span> <span class="pre">(or</span> <span class="pre">0)</span></code> and <code class="docutils literal"><span class="pre">x1</span> <span class="pre">=</span> <span class="pre">t0+20s</span> <span class="pre">(or</span> <span class="pre">20)</span></code>. Thus we have <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">10)</span> <span class="pre">*</span> <span class="pre">((10</span> <span class="pre">-</span> <span class="pre">0)</span> <span class="pre">/</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">0)</span></code> which will reduce to <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">10</span> <span class="pre">*</span> <span class="pre">(10</span> <span class="pre">/</span> <span class="pre">20)</span></code> further reducing to <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">10</span> <span class="pre">*</span> <span class="pre">.5</span></code> and <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">5</span></code>. Therefore <code class="docutils literal"><span class="pre">B</span></code> will give us a <em>guestimated</em> value of <code class="docutils literal"><span class="pre">15</span></code> at <code class="docutils literal"><span class="pre">t0+10s</span></code>.</p>
<p>Iteration continues over every timestamp for which a data point is found for every series returned as a part of the query. The resulting series, using the <strong>sum</strong> aggregator, will look like this:</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="30%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">series</th>
<th class="head">t0</th>
<th class="head">t0+10s</th>
<th class="head">t0+20s</th>
<th class="head">t0+30s</th>
<th class="head">t0+40s</th>
<th class="head">t0+50s</th>
<th class="head">t0+60s</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>A</td>
<td><em>na</em></td>
<td>5</td>
<td><em>na</em></td>
<td>15</td>
<td><em>na</em></td>
<td>5</td>
<td><em>na</em></td>
</tr>
<tr class="row-odd"><td>B</td>
<td>10</td>
<td><em>na</em></td>
<td>20</td>
<td><em>na</em></td>
<td>10</td>
<td><em>na</em></td>
<td>20</td>
</tr>
<tr class="row-even"><td>Interpolated A</td>
<td>&#160;</td>
<td>&#160;</td>
<td>10</td>
<td>&#160;</td>
<td>10</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>Interpolated B</td>
<td>&#160;</td>
<td>15</td>
<td>&#160;</td>
<td>15</td>
<td>&#160;</td>
<td>15</td>
<td><em>na</em></td>
</tr>
<tr class="row-even"><td>Summed Result</td>
<td>10</td>
<td>20</td>
<td>30</td>
<td>25</td>
<td>20</td>
<td>20</td>
<td>20</td>
</tr>
</tbody>
</table>
<p><strong>More Examples:</strong>
For the graphically inclined we have the following examples. An imaginary metric named <code class="docutils literal"><span class="pre">m</span></code> is recorded in OpenTSDB. The &quot;sum of m&quot; is the blue line at the top resulting from a query like <code class="docutils literal"><span class="pre">start=1h-ago&amp;m=sum:m</span></code>. It's made of the sum of the red line for <code class="docutils literal"><span class="pre">host=foo</span></code> and the green line for <code class="docutils literal"><span class="pre">host=bar</span></code>:</p>
<img alt="../../_images/with-lerp.png" src="../../_images/with-lerp.png" />
<p>It seems intuitive from the image above that if you &quot;stack up&quot; the red line and the green line, you'd get the blue line. At any discrete point in time, the blue line has a value that is equal to the sum of the value of the red line and the value of the green line at that time. Without interpolation, you get something rather unintuitive that is harder to make sense of, and which is also a lot less meaningful and useful:</p>
<img alt="../../_images/without-lerp.png" src="../../_images/without-lerp.png" />
<p>Notice how the blue line drops down to the green data point at 18:46:48. No need to be a mathematician or to have taken advanced maths classes to see that interpolation is needed to properly aggregate multiple time series together and get meaningful results.</p>
<p>At the moment OpenTSDB primarily supports <a class="reference external" href="http://en.wikipedia.org/wiki/Linear_interpolation">linear interpolation</a> (sometimes shortened &quot;lerp&quot;) along with some aggregators that will simply substitute zeros or the max or min value. Patches are welcome for those who would like to add other interpolation methods.</p>
<p>Interpolation is only performed at query time when more than one time series are found to match a query. Many metrics collection systems interpolate on <em>write</em> so that you original value is never recorded. OpenTSDB stores your original value and lets you retrieve it at any time.</p>
<p>Here is another slightly more complicated example that came from the mailing list, depicting how multiple time series are aggregated by average:</p>
<img alt="../../_images/aggregation-average_sm.png" src="../../_images/aggregation-average_sm.png" />
<p>The thick blue line with triangles is the an aggregation with the <code class="docutils literal"><span class="pre">avg</span></code> function of multiple time series as per the query <code class="docutils literal"><span class="pre">start=1h-ago&amp;m=avg:duration_seconds</span></code>. As we can see, the resulting time series has one data point at each timestamp of all the underlying time series it aggregates, and that data point is computed by taking the average of the values of all the time series at that timestamp. This is also true for the lonely data point of the squared-purple time series, that temporarily boosted the average until the next data point.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Aggregation functions return integer or double values based on the input data points. If both source values are integers in storage, the resulting calculations will be integers. This means any fractional values resulting from the computation will be lopped off, no rounding will occur. If either data point is a floating point value, the result will be a floating point. However if downsampling or rates are enabled, the result will always be a float.</p>
</div>
</div>
<div class="section" id="downsampling">
<h2>Downsampling</h2>
<p>As mentioned above, interpolation is one means of handling missing data. But some users hate the fact that linear interpolation is a way of <em>lying</em> about the data because it generates phantom values. Instead one means of handling unaligned values is through downsampling. For example, if sources report a value every minute but they're skewed in time across that minute, provide a downsampling on 1 minute for every query across that source data. This will have the result of <em>snapping</em> the values to the same timestamp across each time series so that interpolation is <em>mostly</em> avoided. Interpolation will still occur when a downsampling <em>bucket</em> is missing a value.</p>
<p>See <a class="reference internal" href="downsampling.html"><span class="doc">Downsampling</span></a> for details and examples on avoiding interpolation.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In general it's a good ideal to downsample every query that will incorporate multiple time series.</p>
</div>
</div>
<div class="section" id="available-aggregators">
<h2>Available Aggregators</h2>
<p>The following is a description of the aggregation functions available in OpenTSDB. Note that some should only be used for grouping and others for downsampling.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Aggregator</th>
<th class="head">TSD Version</th>
<th class="head">Description&quot;</th>
<th class="head">Interpolation</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>avg</td>
<td>1.0</td>
<td>Averages the data points</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>count</td>
<td>2.2</td>
<td>The number of raw data points in the set</td>
<td>Zero if missing</td>
</tr>
<tr class="row-even"><td>dev</td>
<td>1.0</td>
<td>Calculates the standard deviation</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>ep50r3</td>
<td>2.2</td>
<td>Calculates the estimated 50th percentile with the R-3 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>ep50r7</td>
<td>2.2</td>
<td>Calculates the estimated 50th percentile with the R-7 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>ep75r3</td>
<td>2.2</td>
<td>Calculates the estimated 75th percentile with the R-3 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>ep75r7</td>
<td>2.2</td>
<td>Calculates the estimated 75th percentile with the R-7 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>ep90r3</td>
<td>2.2</td>
<td>Calculates the estimated 90th percentile with the R-3 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>ep90r7</td>
<td>2.2</td>
<td>Calculates the estimated 90th percentile with the R-7 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>ep95r3</td>
<td>2.2</td>
<td>Calculates the estimated 95th percentile with the R-3 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>ep95r7</td>
<td>2.2</td>
<td>Calculates the estimated 95th percentile with the R-7 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>ep99r3</td>
<td>2.2</td>
<td>Calculates the estimated 99th percentile with the R-3 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>ep99r7</td>
<td>2.2</td>
<td>Calculates the estimated 99th percentile with the R-7 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>ep999r3</td>
<td>2.2</td>
<td>Calculates the estimated 999th percentile with the R-3 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>ep999r7</td>
<td>2.2</td>
<td>Calculates the estimated 999th percentile with the R-7 method *</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>first</td>
<td>2.3</td>
<td>Returns the first data point in the set. Only useful for downsampling, not aggregation.</td>
<td>Indeterminate</td>
</tr>
<tr class="row-even"><td>last</td>
<td>2.3</td>
<td>Returns the last data point in the set. Only useful for downsampling, not aggregation.</td>
<td>Indeterminate</td>
</tr>
<tr class="row-odd"><td>mimmin</td>
<td>2.0</td>
<td>Selects the smallest data point</td>
<td>Maximum if missing</td>
</tr>
<tr class="row-even"><td>mimmax</td>
<td>2.0</td>
<td>Selects the largest data point</td>
<td>Minimum if missing</td>
</tr>
<tr class="row-odd"><td>min</td>
<td>1.0</td>
<td>Selects the smallest data point</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>max</td>
<td>1.0</td>
<td>Selects the largest data point</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>none</td>
<td>2.3</td>
<td>Skips group by aggregation of all time series.</td>
<td>Zero if missing</td>
</tr>
<tr class="row-even"><td>p50</td>
<td>2.2</td>
<td>Calculates the 50th percentile</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>p75</td>
<td>2.2</td>
<td>Calculates the 75th percentile</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>p90</td>
<td>2.2</td>
<td>Calculates the 90th percentile</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>p95</td>
<td>2.2</td>
<td>Calculates the 95th percentile</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>p99</td>
<td>2.2</td>
<td>Calculates the 99th percentile</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>p999</td>
<td>2.2</td>
<td>Calculates the 999th percentile</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-even"><td>sum</td>
<td>1.0</td>
<td>Adds the data points together</td>
<td>Linear Interpolation</td>
</tr>
<tr class="row-odd"><td>zimsum</td>
<td>2.0</td>
<td>Adds the data points together</td>
<td>Zero if missing</td>
</tr>
</tbody>
</table>
<p>* For percentile calculations, see the <a class="reference external" href="http://en.wikipedia.org/wiki/Quantile">Wikipedia</a> article. For high cardinality calculations, using the estimated percentiles may be more performant.</p>
<div class="section" id="avg">
<h3>Avg</h3>
<p>Calculates the average of all values across the downsampling bucket or across multiple time series. This function will perform linear interpolation across time series. It's useful for looking at gauge metrics.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Even though the calculation will usually result in a floating point value, if the data points are recorded as integers, an integer will be returned losing some precision.</p>
</div>
</div>
<div class="section" id="count">
<h3>Count</h3>
<p>Returns the number of data points stored in the series or range. When used to aggregate multiple series, zeros will be substituted. When used with downsampling, it will reflect the number of data points in each downsample <em>bucket</em>. When used in a group-by aggregation, reflects the number of time series with values at a given time.</p>
</div>
<div class="section" id="dev">
<h3>Dev</h3>
<p>Calculates the <a class="reference external" href="http://en.wikipedia.org/wiki/Standard_deviation">standard deviation</a> across a bucket or time series. This function will perform linear interpolation across time series. It's useful for looking at gauge metrics.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Even though the calculation will usually result in a floating point value, if the data points are recorded as integers, an integer will be returned losing some precision.</p>
</div>
</div>
<div class="section" id="estimated-percentiles">
<h3>Estimated Percentiles</h3>
<p>Calculates various percentiles using a choice of algorithms. These are useful for series with many data points as some data may be kicked out of the calculation. When used to aggregate multiple series, the function will perform linear interpolation. See <a class="reference external" href="http://en.wikipedia.org/wiki/Quantile">Wikipedia</a> for details. Implementation is through the <a class="reference external" href="http://commons.apache.org/proper/commons-math/">Apache Math library.</a></p>
</div>
<div class="section" id="first-last">
<h3>First &amp; Last</h3>
<span class="target" id="index-6"></span><p>These aggregators will return the first or the last data point in the downsampling interval. E.g. if a downsample bucket consists of the series <code class="docutils literal"><span class="pre">2,</span> <span class="pre">6,</span> <span class="pre">1,</span> <span class="pre">7</span></code> then the <code class="docutils literal"><span class="pre">first</span></code> aggregator will return <code class="docutils literal"><span class="pre">1</span></code> and <code class="docutils literal"><span class="pre">last</span></code> will return <code class="docutils literal"><span class="pre">7</span></code>. Note that this aggregator is only useful for downsamplers.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">When used as a group-by aggregator, the results are indeterminate as the ordering of time series retrieved from storage and held in memory is not consistent from TSD to TSD or execution to execution.</p>
</div>
</div>
<div class="section" id="max">
<h3>Max</h3>
<p>The inverse of <code class="docutils literal"><span class="pre">min</span></code>, it returns the largest data point from all of the time series or within a time span. This function will perform linear interpolation across time series. It's useful for looking at the upper bounds of gauge metrics.</p>
</div>
<div class="section" id="mimmin">
<h3>MimMin</h3>
<p>The &quot;maximum if missing minimum&quot; function returns only the smallest data point from all of the time series or within the time span. This function will <em>not</em> perform interpolation, instead it will return the maximum value for the type of data specified if the value is missing. This will return the Long.MaxValue for integer points or Double.MaxValue for floating point values. See <a class="reference external" href="http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">Primitive Data Types</a> for details. It's useful for looking at the lower bounds of gauge metrics.</p>
</div>
<div class="section" id="mimmax">
<h3>MimMax</h3>
<p>The &quot;minimum if missing maximum&quot; function returns only the largest data point from all of the time series or within the time span. This function will <em>not</em> perform interpolation, instead it will return the minimum value for the type of data specified if the value is missing. This will return the Long.MinValue for integer points or Double.MinValue for floating point values. See <a class="reference external" href="http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html">Primitive Data Types</a> for details. It's useful for looking at the upper bounds of gauge metrics.</p>
</div>
<div class="section" id="min">
<h3>Min</h3>
<p>Returns only the smallest data point from all of the time series or within the time span. This function will perform linear interpolation across time series. It's useful for looking at the lower bounds of gauge metrics.</p>
</div>
<div class="section" id="none">
<h3>None</h3>
<p>Skips group by aggregation. This aggregator is useful for fetching the <em>raw</em> data from storage as it will return a result set for every time series matching the filters. Note that the query will throw an exception if used with a downsampler.</p>
</div>
<div class="section" id="percentiles">
<h3>Percentiles</h3>
<p>Calculates various percentiles. When used to aggregate multiple series, the function will perform linear interpolation. Implementation is through the <a class="reference external" href="http://commons.apache.org/proper/commons-math/">Apache Math library.</a></p>
</div>
<div class="section" id="sum">
<h3>Sum</h3>
<p>Calculates the sum of all data points from all of the time series or within the time span if down sampling. This is the default aggregation function for the GUI as it's often the most useful when combining multiple time series such as gauges or counters. It performs linear interpolation when data points fail to line up. If you have a distinct series of values that you want to sum and you do not need interpolation, look at <code class="docutils literal"><span class="pre">zimsum</span></code></p>
</div>
<div class="section" id="zimsum">
<h3>ZimSum</h3>
<p>Calculates the sum of all data points at the specified timestamp from all of the time series or within the time span. This function does <em>not</em> perform interpolation, instead it substitutes a <code class="docutils literal"><span class="pre">0</span></code> for missing data points. This can be useful when working with discrete values.</p>
</div>
</div>
<div class="section" id="listing-aggregators">
<h2>Listing Aggregators</h2>
<p>With the HTTP API running on a TSD, users can query the <code class="docutils literal"><span class="pre">/api/aggregators</span></code> to get a list of aggregators implemented on the TSD.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2018, OpenTSDB.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.7.<br/>
    </p>
  </div>
</footer>
  </body>
</html>